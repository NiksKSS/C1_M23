{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d181c6-3f9a-460d-a6f9-7a68e13de54f",
   "metadata": {},
   "source": [
    "C1_M2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ce8d6-e003-4a62-8b6f-de98d97e77b4",
   "metadata": {},
   "source": [
    "Table of contest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ab38e-c7c6-4c42-b263-3dbc6404c5dd",
   "metadata": {},
   "source": [
    "1. Подключение библиотек\n",
    "2. Конфигурация\n",
    "3. Функция предобработки изображения\n",
    "4. Функция аугментации изображения (поворот и вырезание)\n",
    "5. Применение функции предобработки ко всем элементам массива\n",
    "6. Балансировка классов в обучающей выборке\n",
    "7. Анализ структуры датасета\n",
    "8. Создание итогового архива preprocessed_images.zip\n",
    "9. Отчет итогового датасета\n",
    "10. Демонтрация работы аугментаций\n",
    "11. Основной пайплайн"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b84f8-9e75-4684-bf66-e17c1da8c852",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9528b959-b5ca-46b0-ba5b-6867b5eed5e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8923d-5705-4884-ba73-42c0e6292164",
   "metadata": {},
   "source": [
    "2. Конфигурация "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "011651f7-9997-4788-902d-d9ee89e93a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVE_NAME = 'Gauge.zip'\n",
    "TEMP_DIR = 'temp_extract'\n",
    "ORIGINAL_DIR = 'images'\n",
    "PROCESSED_DIR = 'preprocessed_images'\n",
    "TARGET_SIZES = {\n",
    "    'train': 23000,\n",
    "    'test': 1000,\n",
    "    'val': 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596075c5-23aa-414c-ac98-35af9e10d8be",
   "metadata": {},
   "source": [
    "3. Функция предобработки изображения (изменение его размера и цвета)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b64ad894-2f94-4e82-a958-e6a815593507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(src_path, dst_path):\n",
    "    try:\n",
    "        with Image.open(src_path) as img:\n",
    "            img_resized = img.resize((224, 224)).convert('RGB')\n",
    "\n",
    "            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "\n",
    "            img_resized.save(dst_path)\n",
    "\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обработки {src_path}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51884e0c-7468-42cd-9f6a-be1e4d120ed7",
   "metadata": {},
   "source": [
    "4. Функция аугментации изображения (поворот на 15 градусов и добавление черного прямоугольника)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e216d46-b1a2-498d-9219-ef6538b84aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image_path, show_results=False):\n",
    "    base, ext = os.path.splitext(image_path)\n",
    "    tilted_path = f\"{base}_tilted{ext}\"\n",
    "    corrupted_path = f\"{base}_corrupted{ext}\"\n",
    "\n",
    "    if os.path.exists(tilted_path) and os.path.exists(corrupted_path):\n",
    "        if not show_results:\n",
    "            print(f\"Аугментации для {os.path.basename(image_path)} уже существуют\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            original = img.copy()\n",
    "\n",
    "            # Поворот\n",
    "            angle = random.uniform(-15, 15)\n",
    "            rotated = img.rotate(angle, expand=False)\n",
    "\n",
    "            # Добавление черного прямоугольника\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            w, h = img.size\n",
    "            rect_w = random.randint(20, 50)\n",
    "            rect_h = random.randint(20, 50)\n",
    "            x = random.randint(0, w - rect_w)\n",
    "            y = random.randint(0, h - rect_h)\n",
    "            draw.rectangle([x, y, x + rect_w, y + rect_h], fill='black')\n",
    "            corrupted = img\n",
    "\n",
    "            if show_results:\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(original)\n",
    "                ax[0].set_title('Original')\n",
    "                ax[1].imshow(rotated)\n",
    "                ax[1].set_title(f'tilted {angle:.1f}°')\n",
    "                ax[2].imshow(corrupted)\n",
    "                ax[2].set_title('corrupted')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                return\n",
    "\n",
    "            rotated.save(tilted_path)\n",
    "            corrupted.save(corrupted_path)\n",
    "\n",
    "            if not show_results:\n",
    "                print(f\"Созданы аугментации для {os.path.basename(image_path)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка аугментации: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d6f2f-bb4e-42fc-8e05-38de3c93f5e3",
   "metadata": {},
   "source": [
    "5. Применение функции предобработки ко всем элементам массива"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce9c38dc-dddd-4b68-ad94-56d8816976db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    processed = 0\n",
    "    for root, _, files in os.walk(ORIGINAL_DIR):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                src = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(root, ORIGINAL_DIR)\n",
    "                dst = os.path.join(PROCESSED_DIR, rel_path, file)\n",
    "\n",
    "                if preprocess_image(src, dst):\n",
    "                    processed += 1\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021db3c0-9fc2-43e7-a5bc-5380abf010c4",
   "metadata": {},
   "source": [
    "6. Балансировка классов в обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0ffe3c5-f7a2-4b91-8710-a2fe4573b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes():\n",
    "    train_dir = os.path.join(PROCESSED_DIR, 'train')\n",
    "\n",
    "    for class_name in os.listdir(train_dir):\n",
    "        class_dir = os.path.join(train_dir, class_name)\n",
    "\n",
    "        if os.path.isdir(class_dir):\n",
    "            images = [f for f in os.listdir(class_dir)\n",
    "                      if not f.endswith(('_tilted.jpg', '_corrupted.jpg'))]\n",
    "\n",
    "            if images:\n",
    "                selected = os.path.join(class_dir, images[0])\n",
    "                augment_image(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485aa7e-0cc3-42f1-9dfc-402cec666627",
   "metadata": {},
   "source": [
    "7. Анализ структуры датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c9a7497-2609-4818-9516-5943c30cccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset():\n",
    "    sizes = defaultdict(int)\n",
    "    structure = {}\n",
    "\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_dir = os.path.join(PROCESSED_DIR, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "\n",
    "        class_counts = {}\n",
    "        for class_name in os.listdir(split_dir):\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                count = len([f for f in os.listdir(class_dir)\n",
    "                             if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "                class_counts[class_name] = count\n",
    "                sizes[split] += count\n",
    "\n",
    "        structure[split] = {\n",
    "            'classes': len(class_counts),\n",
    "            'total': sizes[split],\n",
    "            'per_class': class_counts\n",
    "        }\n",
    "\n",
    "    return sizes, structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6d1a5-1419-4abc-8fb1-60db58f6c9ab",
   "metadata": {},
   "source": [
    "8. Создание итогового архива preprocessed_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b83adc7-0a5b-48d2-8426-84cf4fbc4701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zip_archive():\n",
    "    print(\"\\nСоздание архива...\")\n",
    "    shutil.make_archive('preprocessed_images', 'zip', PROCESSED_DIR)\n",
    "    print(\"Архив preprocessed_images.zip создан\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d80c9-b527-45b1-a9a6-268fd8f41fdc",
   "metadata": {},
   "source": [
    "9. Отчет итогового датасета (кол-во изображений в каждом датасете)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c238f663-0ad2-46fd-83f8-d8f1bb6517e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(structure):\n",
    "    report = [\n",
    "        \"Структура итогового датасета:\",\n",
    "        \"========================================\",\n",
    "        f\"TRAIN: {structure['train']['total']} изображений \"\n",
    "        f\"({structure['train']['classes']} классов)\",\n",
    "        f\"TEST: {structure['test']['total']} изображений \"\n",
    "        f\"({structure['test']['classes']} классов)\",\n",
    "        f\"VAL: {structure['val']['total']} изображений \"\n",
    "        f\"({structure['val']['classes']} классов)\"\n",
    "    ]\n",
    "    with open('dataset_report.txt', 'w') as f:\n",
    "        f.write('\\n'.join(report))\n",
    "    print(\"\\nОтчет сохранен в dataset_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef82f81-5bd4-4843-8951-e1b263525407",
   "metadata": {},
   "source": [
    "10. Демонстрация работы аугментаций(вывод картинок)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29613c6e-5c29-47e9-a2c5-15369f62f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_augmentations():\n",
    "    samples = []\n",
    "    train_dir = os.path.join(PROCESSED_DIR, 'train')\n",
    "\n",
    "    classes = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
    "    for class_name in random.sample(classes, 2):\n",
    "        class_dir = os.path.join(train_dir, class_name)\n",
    "        images = [f for f in os.listdir(class_dir)\n",
    "                  if not f.endswith(('_tilted.jpg', '_corrupted.jpg'))]\n",
    "        if images:\n",
    "            samples.append(os.path.join(class_dir, images[0]))\n",
    "\n",
    "    for sample in samples:\n",
    "        augment_image(sample, show_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976c437-cdfc-4dcf-bc7a-cbe5129b540c",
   "metadata": {},
   "source": [
    "11. Основной пайплайн ( очистка старых данных, распаковка начального архива)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abc34703-971e-4e10-ac08-60b040893e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка: File is not a zip file\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Очистка\n",
    "        shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
    "        shutil.rmtree(ORIGINAL_DIR, ignore_errors=True)\n",
    "        shutil.rmtree(PROCESSED_DIR, ignore_errors=True)\n",
    "\n",
    "        # Распаковка начального архива\n",
    "        with zipfile.ZipFile(ARCHIVE_NAME, 'r') as zip_ref:\n",
    "            zip_ref.extractall(TEMP_DIR)\n",
    "            print(f\"Архив {ARCHIVE_NAME} распакован\")\n",
    "\n",
    "        # Организация данных\n",
    "        data_root = TEMP_DIR\n",
    "        items = os.listdir(TEMP_DIR)\n",
    "        if len(items) == 1 and os.path.isdir(os.path.join(TEMP_DIR, items[0])):\n",
    "            data_root = os.path.join(TEMP_DIR, items[0])\n",
    "\n",
    "        os.makedirs(ORIGINAL_DIR, exist_ok=True)\n",
    "        for split in ['train', 'test', 'val']:\n",
    "            src = os.path.join(data_root, split)\n",
    "            dst = os.path.join(ORIGINAL_DIR, split)\n",
    "            if os.path.exists(src):\n",
    "                shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "\n",
    "        processed = process_images()\n",
    "        print(f\"Обработано изображений: {processed}\")\n",
    "\n",
    "        balance_classes()\n",
    "\n",
    "        for split, target in TARGET_SIZES.items():\n",
    "            balance_to_target(split, target)\n",
    "\n",
    "        sizes, structure = analyze_dataset()\n",
    "        create_zip_archive()\n",
    "        generate_report(structure)\n",
    "\n",
    "        print(\"\\nИтоговые размеры датасета:\")\n",
    "        print(f\"Обучающая выборка: {sizes['train']}\")\n",
    "        print(f\"Тестовая выборка: {sizes['test']}\")\n",
    "        print(f\"Валидационная выборка: {sizes['val']}\")\n",
    "\n",
    "\n",
    "        demo_augmentations()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {str(e)}\")\n",
    "    finally:\n",
    "        shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6611f164-a08e-44da-a5d9-53e975427c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка: File is not a zip file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "ARCHIVE_NAME = 'Gauge.zip'\n",
    "TEMP_DIR = 'temp_extract'\n",
    "ORIGINAL_DIR = 'images'\n",
    "PROCESSED_DIR = 'preprocessed_images'\n",
    "TARGET_SIZES = {\n",
    "    'train': 23000,\n",
    "    'test': 1000,\n",
    "    'val': 2000\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(src_path, dst_path):\n",
    "    try:\n",
    "        with Image.open(src_path) as img:\n",
    "            img_resized = img.resize((224, 224)).convert('RGB')\n",
    "\n",
    "            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "\n",
    "            img_resized.save(dst_path)\n",
    "\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обработки {src_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def augment_image(image_path, show_results=False):\n",
    "    base, ext = os.path.splitext(image_path)\n",
    "    tilted_path = f\"{base}_tilted{ext}\"\n",
    "    corrupted_path = f\"{base}_corrupted{ext}\"\n",
    "\n",
    "    if os.path.exists(tilted_path) and os.path.exists(corrupted_path):\n",
    "        if not show_results:\n",
    "            print(f\"Аугментации для {os.path.basename(image_path)} уже существуют\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            original = img.copy()\n",
    "\n",
    "            # Поворот\n",
    "            angle = random.uniform(-15, 15)\n",
    "            rotated = img.rotate(angle, expand=False)\n",
    "\n",
    "            # Добавление прямоугольника\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            w, h = img.size\n",
    "            rect_w = random.randint(20, 50)\n",
    "            rect_h = random.randint(20, 50)\n",
    "            x = random.randint(0, w - rect_w)\n",
    "            y = random.randint(0, h - rect_h)\n",
    "            draw.rectangle([x, y, x + rect_w, y + rect_h], fill='black')\n",
    "            corrupted = img\n",
    "\n",
    "            if show_results:\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(original)\n",
    "                ax[0].set_title('Original')\n",
    "                ax[1].imshow(rotated)\n",
    "                ax[1].set_title(f'tilted {angle:.1f}°')\n",
    "                ax[2].imshow(corrupted)\n",
    "                ax[2].set_title('corrupted')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                return\n",
    "\n",
    "            rotated.save(tilted_path)\n",
    "            corrupted.save(corrupted_path)\n",
    "\n",
    "            if not show_results:\n",
    "                print(f\"Созданы аугментации для {os.path.basename(image_path)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка аугментации: {str(e)}\")\n",
    "\n",
    "\n",
    "def process_images():\n",
    "    processed = 0\n",
    "    for root, _, files in os.walk(ORIGINAL_DIR):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                src = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(root, ORIGINAL_DIR)\n",
    "                dst = os.path.join(PROCESSED_DIR, rel_path, file)\n",
    "\n",
    "                if preprocess_image(src, dst):\n",
    "                    processed += 1\n",
    "    return processed\n",
    "\n",
    "\n",
    "def balance_classes():\n",
    "    train_dir = os.path.join(PROCESSED_DIR, 'train')\n",
    "\n",
    "    for class_name in os.listdir(train_dir):\n",
    "        class_dir = os.path.join(train_dir, class_name)\n",
    "\n",
    "        if os.path.isdir(class_dir):\n",
    "            images = [f for f in os.listdir(class_dir)\n",
    "                      if not f.endswith(('_tilted.jpg', '_corrupted.jpg'))]\n",
    "\n",
    "            if images:\n",
    "                selected = os.path.join(class_dir, images[0])\n",
    "                augment_image(selected)\n",
    "               \n",
    "\n",
    "\n",
    "def analyze_dataset():\n",
    "    sizes = defaultdict(int)\n",
    "    structure = {}\n",
    "\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_dir = os.path.join(PROCESSED_DIR, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "\n",
    "        class_counts = {}\n",
    "        for class_name in os.listdir(split_dir):\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                count = len([f for f in os.listdir(class_dir)\n",
    "                             if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "                class_counts[class_name] = count\n",
    "                sizes[split] += count\n",
    "\n",
    "        structure[split] = {\n",
    "            'classes': len(class_counts),\n",
    "            'total': sizes[split],\n",
    "            'per_class': class_counts\n",
    "        }\n",
    "\n",
    "    return sizes, structure\n",
    "\n",
    "\n",
    "def balance_to_target(split, target_size):\n",
    "    split_dir = os.path.join(PROCESSED_DIR, split)\n",
    "\n",
    "    current_files = []\n",
    "    for root, _, files in os.walk(split_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                current_files.append(os.path.join(root, file))\n",
    "\n",
    "    need_add = target_size - len(current_files)\n",
    "    if need_add <= 0:\n",
    "        return\n",
    "\n",
    "\n",
    "    for i in range(need_add):\n",
    "        src = current_files[i % len(current_files)]\n",
    "        base, ext = os.path.splitext(src)\n",
    "        dst = f\"{base}_copy_{i}{ext}\"\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "\n",
    "def create_zip_archive():\n",
    "    print(\"\\nСоздание архива...\")\n",
    "    shutil.make_archive('preprocessed_images', 'zip', PROCESSED_DIR)\n",
    "    print(\"Архив preprocessed_images.zip создан\")\n",
    "\n",
    "\n",
    "def generate_report(structure):\n",
    "    report = [\n",
    "        \"Структура итогового датасета:\",\n",
    "        \"========================================\",\n",
    "        f\"TRAIN: {structure['train']['total']} изображений \"\n",
    "        f\"({structure['train']['classes']} классов)\",\n",
    "        f\"TEST: {structure['test']['total']} изображений \"\n",
    "        f\"({structure['test']['classes']} классов)\",\n",
    "        f\"VAL: {structure['val']['total']} изображений \"\n",
    "        f\"({structure['val']['classes']} классов)\"\n",
    "    ]\n",
    "\n",
    "    with open('dataset_report.txt', 'w') as f:\n",
    "        f.write('\\n'.join(report))\n",
    "    print(\"\\nОтчет сохранен в dataset_report.txt\")\n",
    "\n",
    "\n",
    "def demo_augmentations():\n",
    "    samples = []\n",
    "    train_dir = os.path.join(PROCESSED_DIR, 'train')\n",
    "\n",
    "    classes = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
    "    for class_name in random.sample(classes, 2):\n",
    "        class_dir = os.path.join(train_dir, class_name)\n",
    "        images = [f for f in os.listdir(class_dir)\n",
    "                  if not f.endswith(('_tilted.jpg', '_corrupted.jpg'))]\n",
    "        if images:\n",
    "            samples.append(os.path.join(class_dir, images[0]))\n",
    "\n",
    "    for sample in samples:\n",
    "        augment_image(sample, show_results=True)\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
    "        shutil.rmtree(ORIGINAL_DIR, ignore_errors=True)\n",
    "        shutil.rmtree(PROCESSED_DIR, ignore_errors=True)\n",
    "\n",
    "        with zipfile.ZipFile(ARCHIVE_NAME, 'r') as zip_ref:\n",
    "            zip_ref.extractall(TEMP_DIR)\n",
    "            print(f\"Архив {ARCHIVE_NAME} распакован\")\n",
    "\n",
    "\n",
    "        data_root = TEMP_DIR\n",
    "        items = os.listdir(TEMP_DIR)\n",
    "        if len(items) == 1 and os.path.isdir(os.path.join(TEMP_DIR, items[0])):\n",
    "            data_root = os.path.join(TEMP_DIR, items[0])\n",
    "\n",
    "        os.makedirs(ORIGINAL_DIR, exist_ok=True)\n",
    "        for split in ['train', 'test', 'val']:\n",
    "            src = os.path.join(data_root, split)\n",
    "            dst = os.path.join(ORIGINAL_DIR, split)\n",
    "            if os.path.exists(src):\n",
    "                shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "\n",
    "        processed = process_images()\n",
    "        balance_classes()\n",
    "\n",
    "        for split, target in TARGET_SIZES.items():\n",
    "            balance_to_target(split, target)\n",
    "\n",
    "\n",
    "        sizes, structure = analyze_dataset()\n",
    "        create_zip_archive()\n",
    "        generate_report(structure)\n",
    "\n",
    "        print(\"\\nИтоговые размеры датасета:\")\n",
    "        print(f\"Обучающая выборка: {sizes['train']}\")\n",
    "        print(f\"Тестовая выборка: {sizes['test']}\")\n",
    "        print(f\"Валидационная выборка: {sizes['val']}\")\n",
    "\n",
    "        demo_augmentations()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {str(e)}\")\n",
    "    finally:\n",
    "        shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
